{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd \n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline \n",
    "\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import VotingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# this only transforms the idhogar field, the other things this function used to do are done elsewhere\n",
    "def encode_data(df):\n",
    "    df['idhogar'] = LabelEncoder().fit_transform(df['idhogar'])\n",
    "\n",
    "# plot feature importance for sklearn decision trees    \n",
    "def feature_importance(forest, X_train, display_results=True):\n",
    "    ranked_list = []\n",
    "    zero_features = []\n",
    "    \n",
    "    importances = forest.feature_importances_\n",
    "\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    \n",
    "    if display_results:\n",
    "        # Print the feature ranking\n",
    "        print(\"Feature ranking:\")\n",
    "\n",
    "    for f in range(X_train.shape[1]):\n",
    "        if display_results:\n",
    "            print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]) + \" - \" + X_train.columns[indices[f]])\n",
    "        \n",
    "        ranked_list.append(X_train.columns[indices[f]])\n",
    "        \n",
    "        if importances[indices[f]] == 0.0:\n",
    "            zero_features.append(X_train.columns[indices[f]])\n",
    "            \n",
    "    return ranked_list, zero_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_features(df):\n",
    "    feats_div = [('children_fraction', 'r4t1', 'r4t3'), \n",
    "                 ('working_man_fraction', 'r4h2', 'r4t3'),\n",
    "                 ('all_man_fraction', 'r4h3', 'r4t3'),\n",
    "                 ('human_density', 'tamviv', 'rooms'),\n",
    "                 ('human_bed_density', 'tamviv', 'bedrooms'),\n",
    "                 ('rent_per_person', 'v2a1', 'r4t3'),\n",
    "                 ('rent_per_room', 'v2a1', 'rooms'),\n",
    "                 ('mobile_density', 'qmobilephone', 'r4t3'),\n",
    "                 ('tablet_density', 'v18q1', 'r4t3'),\n",
    "                 ('mobile_adult_density', 'qmobilephone', 'r4t2'),\n",
    "                 ('tablet_adult_density', 'v18q1', 'r4t2'),\n",
    "                ]\n",
    "    \n",
    "    feats_sub = [('people_not_living', 'tamhog', 'tamviv'),\n",
    "                 ('people_weird_stat', 'tamhog', 'r4t3')]\n",
    "\n",
    "    for f_new, f1, f2 in feats_div:\n",
    "        df['fe_' + f_new] = (df[f1] / df[f2]).astype(np.float32)       \n",
    "    for f_new, f1, f2 in feats_sub:\n",
    "        df['fe_' + f_new] = (df[f1] - df[f2]).astype(np.float32)\n",
    "    \n",
    "    # aggregation rules over household\n",
    "    aggs_num = {'age': ['min', 'max', 'mean'],\n",
    "                'escolari': ['min', 'max', 'mean']\n",
    "               }\n",
    "    \n",
    "    aggs_cat = {'dis': ['mean']}\n",
    "    for s_ in ['estadocivil', 'parentesco', 'instlevel']:\n",
    "        for f_ in [f_ for f_ in df.columns if f_.startswith(s_)]:\n",
    "            aggs_cat[f_] = ['mean', 'count']\n",
    "\n",
    "    # aggregation over household\n",
    "    for name_, df_ in [('18', df.query('age >= 18'))]:\n",
    "        df_agg = df_.groupby('idhogar').agg({**aggs_num, **aggs_cat}).astype(np.float32)\n",
    "        df_agg.columns = pd.Index(['agg' + name_ + '_' + e[0] + \"_\" + e[1].upper() for e in df_agg.columns.tolist()])\n",
    "        df = df.join(df_agg, how='left', on='idhogar')\n",
    "        del df_agg\n",
    "\n",
    "    # Drop id's\n",
    "    df.drop(['Id'], axis=1, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert one hot encoded fields to label encoding\n",
    "def convert_OHE2LE(df):\n",
    "    tmp_df = df.copy(deep=True)\n",
    "    for s_ in ['pared', 'piso', 'techo', 'abastagua', 'sanitario', 'energcocinar', 'elimbasu', \n",
    "               'epared', 'etecho', 'eviv', 'estadocivil', 'parentesco', \n",
    "               'instlevel', 'lugar', 'tipovivi',\n",
    "               'manual_elec']:\n",
    "        if 'manual_' not in s_:\n",
    "            cols_s_ = [f_ for f_ in df.columns if f_.startswith(s_)]\n",
    "        elif 'elec' in s_:\n",
    "            cols_s_ = ['public', 'planpri', 'noelec', 'coopele']\n",
    "        sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "        #deal with those OHE, where there is a sum over columns == 0\n",
    "        if 0 in sum_ohe:\n",
    "            print('The OHE in {} is incomplete. A new column will be added before label encoding'\n",
    "                  .format(s_))\n",
    "            # dummy colmn name to be added\n",
    "            col_dummy = s_+'_dummy'\n",
    "            # add the column to the dataframe\n",
    "            tmp_df[col_dummy] = (tmp_df[cols_s_].sum(axis=1) == 0).astype(np.int8)\n",
    "            # add the name to the list of columns to be label-encoded\n",
    "            cols_s_.append(col_dummy)\n",
    "            # proof-check, that now the category is complete\n",
    "            sum_ohe = tmp_df[cols_s_].sum(axis=1).unique()\n",
    "            if 0 in sum_ohe:\n",
    "                 print(\"The category completion did not work\")\n",
    "        tmp_cat = tmp_df[cols_s_].idxmax(axis=1)\n",
    "        tmp_df[s_ + '_LE'] = LabelEncoder().fit_transform(tmp_cat).astype(np.int16)\n",
    "        if 'parentesco1' in cols_s_:\n",
    "            cols_s_.remove('parentesco1')\n",
    "        tmp_df.drop(cols_s_, axis=1, inplace=True)\n",
    "    return tmp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./costarica_train.csv')\n",
    "test = pd.read_csv('./costarica_test.csv')\n",
    "\n",
    "test_ids = test.Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(df_):\n",
    "    # encode the idhogar\n",
    "    encode_data(df_)\n",
    "    \n",
    "    # create aggregate features\n",
    "    return do_features(df_)\n",
    "\n",
    "train = process_df(train)\n",
    "test = process_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some dependencies are Na, fill those with the square root of the square\n",
    "train['dependency'] = np.sqrt(train['SQBdependency'])\n",
    "test['dependency'] = np.sqrt(test['SQBdependency'])\n",
    "\n",
    "# fill \"no\"s for education with 0s\n",
    "train.loc[train['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "train.loc[train['edjefe'] == \"no\", \"edjefe\"] = 0\n",
    "test.loc[test['edjefa'] == \"no\", \"edjefa\"] = 0\n",
    "test.loc[test['edjefe'] == \"no\", \"edjefe\"] = 0\n",
    "\n",
    "# if education is \"yes\" and person is head of household, fill with escolari\n",
    "train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"edjefa\"] = train.loc[(train['edjefa'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n",
    "train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"edjefe\"] = train.loc[(train['edjefe'] == \"yes\") & (train['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"edjefa\"] = test.loc[(test['edjefa'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n",
    "test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"edjefe\"] = test.loc[(test['edjefe'] == \"yes\") & (test['parentesco1'] == 1), \"escolari\"]\n",
    "\n",
    "# this field is supposed to be interaction between gender and escolari, but it isn't clear what \"yes\" means, let's fill it with 4\n",
    "train.loc[train['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "train.loc[train['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "test.loc[test['edjefa'] == \"yes\", \"edjefa\"] = 4\n",
    "test.loc[test['edjefe'] == \"yes\", \"edjefe\"] = 4\n",
    "\n",
    "# convert to int for our models\n",
    "train['edjefe'] = train['edjefe'].astype(\"int\")\n",
    "train['edjefa'] = train['edjefa'].astype(\"int\")\n",
    "test['edjefe'] = test['edjefe'].astype(\"int\")\n",
    "test['edjefa'] = test['edjefa'].astype(\"int\")\n",
    "\n",
    "# create feature with max education of either head of household\n",
    "train['edjef'] = np.max(train[['edjefa','edjefe']], axis=1)\n",
    "test['edjef'] = np.max(test[['edjefa','edjefe']], axis=1)\n",
    "\n",
    "# fill some nas\n",
    "train['v2a1']=train['v2a1'].fillna(0)\n",
    "test['v2a1']=test['v2a1'].fillna(0)\n",
    "\n",
    "test['v18q1']=test['v18q1'].fillna(0)\n",
    "train['v18q1']=train['v18q1'].fillna(0)\n",
    "\n",
    "train['rez_esc']=train['rez_esc'].fillna(0)\n",
    "test['rez_esc']=test['rez_esc'].fillna(0)\n",
    "\n",
    "train.loc[train.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "train.loc[train.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n",
    "\n",
    "test.loc[test.meaneduc.isnull(), \"meaneduc\"] = 0\n",
    "test.loc[test.SQBmeaned.isnull(), \"SQBmeaned\"] = 0\n",
    "\n",
    "# fix some inconsistencies in the data - some rows indicate both that the household does and does not have a toilet, \n",
    "# if there is no water we'll assume they do not\n",
    "train.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"v14a\"] = 0\n",
    "train.loc[(train.v14a ==  1) & (train.sanitario1 ==  1) & (train.abastaguano == 0), \"sanitario1\"] = 0\n",
    "\n",
    "test.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"v14a\"] = 0\n",
    "test.loc[(test.v14a ==  1) & (test.sanitario1 ==  1) & (test.abastaguano == 0), \"sanitario1\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_apply_func(train_, test_, func_):\n",
    "    test_['Target'] = 0\n",
    "    xx = pd.concat([train_, test_])\n",
    "\n",
    "    xx_func = func_(xx)\n",
    "    train_ = xx_func.iloc[:train_.shape[0], :]\n",
    "    test_  = xx_func.iloc[train_.shape[0]:, :].drop('Target', axis=1)\n",
    "\n",
    "    del xx, xx_func\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The OHE in techo is incomplete. A new column will be added before label encoding\n",
      "The OHE in instlevel is incomplete. A new column will be added before label encoding\n",
      "The OHE in manual_elec is incomplete. A new column will be added before label encoding\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_apply_func(train, test, convert_OHE2LE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geo aggregates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_2_ohe = ['eviv_LE', 'etecho_LE', 'epared_LE', 'elimbasu_LE', \n",
    "              'energcocinar_LE', 'sanitario_LE', 'manual_elec_LE',\n",
    "              'pared_LE']\n",
    "cols_nums = ['age', 'meaneduc', 'dependency', \n",
    "             'hogar_nin', 'hogar_adul', 'hogar_mayor', 'hogar_total',\n",
    "             'bedrooms', 'overcrowding']\n",
    "\n",
    "def convert_geo2aggs(df_):\n",
    "    tmp_df = pd.concat([df_[(['lugar_LE', 'idhogar']+cols_nums)],\n",
    "                        pd.get_dummies(df_[cols_2_ohe], \n",
    "                                       columns=cols_2_ohe)],axis=1)\n",
    "\n",
    "    geo_agg = tmp_df.groupby(['lugar_LE','idhogar']).mean().groupby('lugar_LE').mean().astype(np.float32)\n",
    "    geo_agg.columns = pd.Index(['geo_' + e for e in geo_agg.columns.tolist()])\n",
    "    \n",
    "    del tmp_df\n",
    "    return df_.join(geo_agg, how='left', on='lugar_LE')\n",
    "\n",
    "# add some aggregates by geography\n",
    "train, test = train_test_apply_func(train, test, convert_geo2aggs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['num_over_18'] = 0\n",
    "train['num_over_18'] = train[train.age >= 18].groupby('idhogar').transform(\"count\")\n",
    "train['num_over_18'] = train.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "train['num_over_18'] = train['num_over_18'].fillna(0)\n",
    "\n",
    "test['num_over_18'] = 0\n",
    "test['num_over_18'] = test[test.age >= 18].groupby('idhogar').transform(\"count\")\n",
    "test['num_over_18'] = test.groupby(\"idhogar\")[\"num_over_18\"].transform(\"max\")\n",
    "test['num_over_18'] = test['num_over_18'].fillna(0)\n",
    "\n",
    "# add some extra features, these were taken from another kernel\n",
    "def extract_features(df):\n",
    "    df['bedrooms_to_rooms'] = df['bedrooms']/df['rooms']\n",
    "    df['rent_to_rooms'] = df['v2a1']/df['rooms']\n",
    "    df['tamhog_to_rooms'] = df['tamhog']/df['rooms'] # tamhog - size of the household\n",
    "    df['r4t3_to_tamhog'] = df['r4t3']/df['tamhog'] # r4t3 - Total persons in the household\n",
    "    df['r4t3_to_rooms'] = df['r4t3']/df['rooms'] # r4t3 - Total persons in the household\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/df['r4t3'] # rent to people in household\n",
    "    df['v2a1_to_r4t3'] = df['v2a1']/(df['r4t3'] - df['r4t1']) # rent to people under age 12\n",
    "    df['hhsize_to_rooms'] = df['hhsize']/df['rooms'] # rooms per person\n",
    "    df['rent_to_hhsize'] = df['v2a1']/df['hhsize'] # rent to household size\n",
    "    df['rent_to_over_18'] = df['v2a1']/df['num_over_18']\n",
    "    # some households have no one over 18, use the total rent for those\n",
    "    df.loc[df.num_over_18 == 0, \"rent_to_over_18\"] = df[df.num_over_18 == 0].v2a1\n",
    "    \n",
    "extract_features(train)    \n",
    "extract_features(test)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "needless_cols = ['r4t3', 'tamhog', 'tamviv', 'hhsize', 'v18q', 'v14a', 'agesq',\n",
    "                 'mobilephone', 'female', ]\n",
    "\n",
    "instlevel_cols = [s for s in train.columns.tolist() if 'instlevel' in s]\n",
    "\n",
    "needless_cols.extend(instlevel_cols)\n",
    "\n",
    "train = train.drop(needless_cols, axis=1)\n",
    "test = test.drop(needless_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(train, y, sample_weight=None, households=None, test_percentage=0.20, seed=None):\n",
    "    # uncomment for extra randomness\n",
    "#     np.random.seed(seed=seed)\n",
    "    \n",
    "    train2 = train.copy()\n",
    "    \n",
    "    # pick some random households to use for the test data\n",
    "    cv_hhs = np.random.choice(households, size=int(len(households) * test_percentage), replace=False)\n",
    "    \n",
    "    # select households which are in the random selection\n",
    "    cv_idx = np.isin(households, cv_hhs)\n",
    "    X_test = train2[cv_idx]\n",
    "    y_test = y[cv_idx]\n",
    "\n",
    "    X_train = train2[~cv_idx]\n",
    "    y_train = y[~cv_idx]\n",
    "    \n",
    "    if sample_weight is not None:\n",
    "        y_train_weights = sample_weight[~cv_idx]\n",
    "        return X_train, y_train, X_test, y_test, y_train_weights\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.query('parentesco1==1')\n",
    "# X = train.copy()\n",
    "\n",
    "# pull out and drop the target variable\n",
    "y = X['Target'] - 1\n",
    "X = X.drop(['Target'], axis=1)\n",
    "\n",
    "np.random.seed(seed=None)\n",
    "\n",
    "train2 = X.copy()\n",
    "\n",
    "train_hhs = train2.idhogar\n",
    "\n",
    "households = train2.idhogar.unique()\n",
    "cv_hhs = np.random.choice(households, size=int(len(households) * 0.15), replace=False)\n",
    "\n",
    "cv_idx = np.isin(train2.idhogar, cv_hhs)\n",
    "\n",
    "X_test = train2[cv_idx]\n",
    "y_test = y[cv_idx]\n",
    "\n",
    "X_train = train2[~cv_idx]\n",
    "y_train = y[~cv_idx]\n",
    "\n",
    "# train on entire dataset\n",
    "X_train = train2\n",
    "y_train = y\n",
    "\n",
    "train_households = X_train.idhogar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_weights = class_weight.compute_sample_weight('balanced', y_train, indices=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_drop_features = [\n",
    " 'agg18_estadocivil1_MEAN',\n",
    " 'agg18_estadocivil6_COUNT',\n",
    " 'agg18_estadocivil7_COUNT',\n",
    " 'agg18_parentesco10_COUNT',\n",
    " 'agg18_parentesco11_COUNT',\n",
    " 'agg18_parentesco12_COUNT',\n",
    " 'agg18_parentesco1_COUNT',\n",
    " 'agg18_parentesco2_COUNT',\n",
    " 'agg18_parentesco3_COUNT',\n",
    " 'agg18_parentesco4_COUNT',\n",
    " 'agg18_parentesco5_COUNT',\n",
    " 'agg18_parentesco6_COUNT',\n",
    " 'agg18_parentesco7_COUNT',\n",
    " 'agg18_parentesco8_COUNT',\n",
    " 'agg18_parentesco9_COUNT',\n",
    " 'geo_elimbasu_LE_4',\n",
    " 'geo_energcocinar_LE_1',\n",
    " 'geo_energcocinar_LE_2',\n",
    " 'geo_epared_LE_0',\n",
    " 'geo_hogar_mayor',\n",
    " 'geo_manual_elec_LE_2',\n",
    " 'geo_pared_LE_3',\n",
    " 'geo_pared_LE_4',\n",
    " 'geo_pared_LE_5',\n",
    " 'geo_pared_LE_6',\n",
    " 'num_over_18',\n",
    " 'parentesco_LE',\n",
    " 'rez_esc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_drop_cols = extra_drop_features + [\"idhogar\",  'parentesco1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_parameters = {'max_depth':35, 'eta':0.1, 'silent':0, 'objective':'multi:softmax', 'min_child_weight': 1, 'num_class': 4, 'gamma': 2.0, 'colsample_bylevel': 0.9, 'subsample': 0.84, 'colsample_bytree': 0.88, 'reg_lambda': 0.40 }\n",
    "# 5\n",
    "opt_parameters = {'max_depth':35, 'eta':0.15, 'silent':1, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 2.5, 'colsample_bylevel': 1, 'subsample': 0.95, 'colsample_bytree': 0.85, 'reg_lambda': 0.35 }\n",
    "# 6\n",
    "# opt_parameters = {'max_depth':35, 'eta':0.15, 'silent':0, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 2.75, 'colsample_bylevel': 0.95, 'subsample': 0.95, 'colsample_bytree': 0.85, 'reg_lambda': 0.35 }\n",
    "# # 7\n",
    "# opt_parameters = {'max_depth':35, 'eta':0.12, 'silent':0, 'objective':'multi:softmax', 'min_child_weight': 2, 'num_class': 4, 'gamma': 3.25, 'colsample_bylevel': 0.95, 'subsample': 0.88, 'colsample_bytree': 0.88, 'reg_lambda': 0.35 }\n",
    "\n",
    "def evaluate_macroF1_lgb(predictions, truth):  \n",
    "    # this follows the discussion in https://github.com/Microsoft/LightGBM/issues/1483\n",
    "    pred_labels = predictions.argmax(axis=1)\n",
    "    truth = truth.get_label()\n",
    "    f1 = f1_score(truth, pred_labels, average='macro')\n",
    "    return ('macroF1', 1-f1) \n",
    "\n",
    "fit_params={\"early_stopping_rounds\":500,\n",
    "            \"eval_metric\" : evaluate_macroF1_lgb, \n",
    "            \"eval_set\" : [(X_train,y_train), (X_test,y_test)],\n",
    "            'verbose': False,\n",
    "           }\n",
    "\n",
    "def learning_rate_power_0997(current_iter):\n",
    "    base_learning_rate = 0.1\n",
    "    min_learning_rate = 0.02\n",
    "    lr = base_learning_rate  * np.power(.995, current_iter)\n",
    "    return max(lr, min_learning_rate)\n",
    "\n",
    "fit_params['verbose'] = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(100)\n",
    "\n",
    "def _parallel_fit_estimator(estimator1, X, y, sample_weight=None, threshold=True, **fit_params):\n",
    "    estimator = clone(estimator1)\n",
    "    \n",
    "    # randomly split the data so we have a test set for early stopping\n",
    "    if sample_weight is not None:\n",
    "        X_train, y_train, X_test, y_test, y_train_weight = split_data(X, y, sample_weight, households=train_households)\n",
    "    else:\n",
    "        X_train, y_train, X_test, y_test = split_data(X, y, None, households=train_households)\n",
    "        \n",
    "    # update the fit params with our new split\n",
    "    fit_params[\"eval_set\"] = [(X_test,y_test)]\n",
    "    \n",
    "    # fit the estimator\n",
    "    if sample_weight is not None:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(X_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(X_train, y_train, sample_weight=y_train_weight, **fit_params)\n",
    "    else:\n",
    "        if isinstance(estimator1, ExtraTreesClassifier) or isinstance(estimator1, RandomForestClassifier):\n",
    "            estimator.fit(X_train, y_train)\n",
    "        else:\n",
    "            _ = estimator.fit(X_train, y_train, **fit_params)\n",
    "    \n",
    "    if not isinstance(estimator1, ExtraTreesClassifier) and not isinstance(estimator1, RandomForestClassifier) and not isinstance(estimator1, xgb.XGBClassifier):\n",
    "        best_cv_round = np.argmax(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_cv = np.max(estimator.evals_result_['validation_0']['mlogloss'])\n",
    "        best_train = estimator.evals_result_['train']['macroF1'][best_cv_round]\n",
    "    else:\n",
    "        best_train = f1_score(y_train, estimator.predict(X_train), average=\"macro\")\n",
    "        best_cv = f1_score(y_test, estimator.predict(X_test), average=\"macro\")\n",
    "        print(\"Train F1:\", best_train)\n",
    "        print(\"Test F1:\", best_cv)\n",
    "        \n",
    "    # reject some estimators based on their performance on train and test sets\n",
    "    if threshold:\n",
    "        # if the valid score is very high we'll allow a little more leeway with the train scores\n",
    "        if ((best_cv > 0.37) and (best_train > 0.75)) or ((best_cv > 0.44) and (best_train > 0.65)):\n",
    "            return estimator\n",
    "\n",
    "        # else recurse until we get a better one\n",
    "        else:\n",
    "            print(\"Unacceptable!!! Trying again...\")\n",
    "            return _parallel_fit_estimator(estimator1, X, y, sample_weight=sample_weight, **fit_params)\n",
    "    \n",
    "    else:\n",
    "        return estimator\n",
    "    \n",
    "class VotingClassifierLGBM(VotingClassifier):\n",
    "    '''\n",
    "    This implements the fit method of the VotingClassifier propagating fit_params\n",
    "    '''\n",
    "    def fit(self, X, y, sample_weight=None, threshold=True, **fit_params):\n",
    "        \n",
    "        if isinstance(y, np.ndarray) and len(y.shape) > 1 and y.shape[1] > 1:\n",
    "            raise NotImplementedError('Multilabel and multi-output'\n",
    "                                      ' classification is not supported.')\n",
    "\n",
    "        if self.voting not in ('soft', 'hard'):\n",
    "            raise ValueError(\"Voting must be 'soft' or 'hard'; got (voting=%r)\"\n",
    "                             % self.voting)\n",
    "\n",
    "        if self.estimators is None or len(self.estimators) == 0:\n",
    "            raise AttributeError('Invalid `estimators` attribute, `estimators`'\n",
    "                                 ' should be a list of (string, estimator)'\n",
    "                                 ' tuples')\n",
    "\n",
    "        if (self.weights is not None and\n",
    "                len(self.weights) != len(self.estimators)):\n",
    "            raise ValueError('Number of classifiers and weights must be equal'\n",
    "                             '; got %d weights, %d estimators'\n",
    "                             % (len(self.weights), len(self.estimators)))\n",
    "\n",
    "        names, clfs = zip(*self.estimators)\n",
    "        self._validate_names(names)\n",
    "\n",
    "        n_isnone = np.sum([clf is None for _, clf in self.estimators])\n",
    "        if n_isnone == len(self.estimators):\n",
    "            raise ValueError('All estimators are None. At least one is '\n",
    "                             'required to be a classifier!')\n",
    "\n",
    "        self.le_ = LabelEncoder().fit(y)\n",
    "        self.classes_ = self.le_.classes_\n",
    "        self.estimators_ = []\n",
    "\n",
    "        transformed_y = self.le_.transform(y)\n",
    "\n",
    "        self.estimators_ = joblib.Parallel(n_jobs=self.n_jobs)(\n",
    "                joblib.delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n",
    "                                                 sample_weight=sample_weight, threshold=threshold, **fit_params)\n",
    "                for clf in clfs if clf is not None)\n",
    "\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:32:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:32:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29894\tvalidation_0-macroF1:0.63874\n",
      "[50]\tvalidation_0-mlogloss:0.89615\tvalidation_0-macroF1:0.56756\n",
      "[100]\tvalidation_0-mlogloss:0.89371\tvalidation_0-macroF1:0.55565\n",
      "[150]\tvalidation_0-mlogloss:0.89062\tvalidation_0-macroF1:0.56537\n",
      "[200]\tvalidation_0-mlogloss:0.89161\tvalidation_0-macroF1:0.56447\n",
      "[250]\tvalidation_0-mlogloss:0.89255\tvalidation_0-macroF1:0.56603\n",
      "[299]\tvalidation_0-mlogloss:0.89179\tvalidation_0-macroF1:0.56650\n",
      "Train F1: 0.9115660908746297\n",
      "Test F1: 0.44462641001160175\n",
      "[12:32:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:32:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30399\tvalidation_0-macroF1:0.62540\n",
      "[50]\tvalidation_0-mlogloss:0.91589\tvalidation_0-macroF1:0.58098\n",
      "[100]\tvalidation_0-mlogloss:0.91543\tvalidation_0-macroF1:0.59476\n",
      "[150]\tvalidation_0-mlogloss:0.91787\tvalidation_0-macroF1:0.60346\n",
      "[200]\tvalidation_0-mlogloss:0.91642\tvalidation_0-macroF1:0.60225\n",
      "[250]\tvalidation_0-mlogloss:0.91610\tvalidation_0-macroF1:0.60209\n",
      "[299]\tvalidation_0-mlogloss:0.91594\tvalidation_0-macroF1:0.60731\n",
      "Train F1: 0.8976233528333496\n",
      "Test F1: 0.4299722420279911\n",
      "[12:33:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:33:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30003\tvalidation_0-macroF1:0.60316\n",
      "[50]\tvalidation_0-mlogloss:0.94443\tvalidation_0-macroF1:0.59214\n",
      "[100]\tvalidation_0-mlogloss:0.93843\tvalidation_0-macroF1:0.57918\n",
      "[150]\tvalidation_0-mlogloss:0.93847\tvalidation_0-macroF1:0.58042\n",
      "[200]\tvalidation_0-mlogloss:0.93756\tvalidation_0-macroF1:0.57726\n",
      "[250]\tvalidation_0-mlogloss:0.93589\tvalidation_0-macroF1:0.58541\n",
      "[299]\tvalidation_0-mlogloss:0.93606\tvalidation_0-macroF1:0.58968\n",
      "Train F1: 0.9128351179853464\n",
      "Test F1: 0.4326931582349539\n",
      "[12:33:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:33:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30547\tvalidation_0-macroF1:0.62321\n",
      "[50]\tvalidation_0-mlogloss:0.92165\tvalidation_0-macroF1:0.56081\n",
      "[100]\tvalidation_0-mlogloss:0.91869\tvalidation_0-macroF1:0.55783\n",
      "[150]\tvalidation_0-mlogloss:0.91620\tvalidation_0-macroF1:0.54999\n",
      "[200]\tvalidation_0-mlogloss:0.91636\tvalidation_0-macroF1:0.55482\n",
      "[250]\tvalidation_0-mlogloss:0.91588\tvalidation_0-macroF1:0.55061\n",
      "[299]\tvalidation_0-mlogloss:0.91556\tvalidation_0-macroF1:0.54736\n",
      "Train F1: 0.9273238446441445\n",
      "Test F1: 0.45331548653917075\n",
      "[12:34:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:34:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30109\tvalidation_0-macroF1:0.63195\n",
      "[50]\tvalidation_0-mlogloss:0.92433\tvalidation_0-macroF1:0.60566\n",
      "[100]\tvalidation_0-mlogloss:0.92053\tvalidation_0-macroF1:0.59748\n",
      "[150]\tvalidation_0-mlogloss:0.91912\tvalidation_0-macroF1:0.60108\n",
      "[200]\tvalidation_0-mlogloss:0.91950\tvalidation_0-macroF1:0.61223\n",
      "[250]\tvalidation_0-mlogloss:0.91865\tvalidation_0-macroF1:0.61383\n",
      "[299]\tvalidation_0-mlogloss:0.91853\tvalidation_0-macroF1:0.60909\n",
      "Train F1: 0.8604328364026029\n",
      "Test F1: 0.4192263582825215\n",
      "[12:34:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:34:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30172\tvalidation_0-macroF1:0.61078\n",
      "[50]\tvalidation_0-mlogloss:0.90473\tvalidation_0-macroF1:0.58278\n",
      "[100]\tvalidation_0-mlogloss:0.90000\tvalidation_0-macroF1:0.57990\n",
      "[150]\tvalidation_0-mlogloss:0.89396\tvalidation_0-macroF1:0.58043\n",
      "[200]\tvalidation_0-mlogloss:0.89226\tvalidation_0-macroF1:0.57862\n",
      "[250]\tvalidation_0-mlogloss:0.89228\tvalidation_0-macroF1:0.58604\n",
      "[299]\tvalidation_0-mlogloss:0.89270\tvalidation_0-macroF1:0.58820\n",
      "Train F1: 0.927086687566341\n",
      "Test F1: 0.42500017325799716\n",
      "[12:35:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:35:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30351\tvalidation_0-macroF1:0.64047\n",
      "[50]\tvalidation_0-mlogloss:0.90510\tvalidation_0-macroF1:0.58320\n",
      "[100]\tvalidation_0-mlogloss:0.90194\tvalidation_0-macroF1:0.58600\n",
      "[150]\tvalidation_0-mlogloss:0.90231\tvalidation_0-macroF1:0.58331\n",
      "[200]\tvalidation_0-mlogloss:0.90319\tvalidation_0-macroF1:0.57922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[250]\tvalidation_0-mlogloss:0.90326\tvalidation_0-macroF1:0.58032\n",
      "[299]\tvalidation_0-mlogloss:0.90476\tvalidation_0-macroF1:0.57784\n",
      "Train F1: 0.9131085061977701\n",
      "Test F1: 0.42540312297831107\n",
      "[12:35:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:35:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30457\tvalidation_0-macroF1:0.66229\n",
      "[50]\tvalidation_0-mlogloss:0.92731\tvalidation_0-macroF1:0.62286\n",
      "[100]\tvalidation_0-mlogloss:0.92147\tvalidation_0-macroF1:0.62384\n",
      "[150]\tvalidation_0-mlogloss:0.92070\tvalidation_0-macroF1:0.63108\n",
      "[200]\tvalidation_0-mlogloss:0.91867\tvalidation_0-macroF1:0.63529\n",
      "[250]\tvalidation_0-mlogloss:0.91730\tvalidation_0-macroF1:0.62598\n",
      "[299]\tvalidation_0-mlogloss:0.91654\tvalidation_0-macroF1:0.63122\n",
      "Train F1: 0.9039317978478034\n",
      "Test F1: 0.3870640568511129\n",
      "[12:36:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:36:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29708\tvalidation_0-macroF1:0.62412\n",
      "[50]\tvalidation_0-mlogloss:0.88409\tvalidation_0-macroF1:0.56213\n",
      "[100]\tvalidation_0-mlogloss:0.88135\tvalidation_0-macroF1:0.55805\n",
      "[150]\tvalidation_0-mlogloss:0.88174\tvalidation_0-macroF1:0.55302\n",
      "[200]\tvalidation_0-mlogloss:0.87978\tvalidation_0-macroF1:0.54801\n",
      "[250]\tvalidation_0-mlogloss:0.87887\tvalidation_0-macroF1:0.54403\n",
      "[299]\tvalidation_0-mlogloss:0.87894\tvalidation_0-macroF1:0.54671\n",
      "Train F1: 0.926590037660807\n",
      "Test F1: 0.45596696580867907\n",
      "[12:36:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:36:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30941\tvalidation_0-macroF1:0.67391\n",
      "[50]\tvalidation_0-mlogloss:0.90405\tvalidation_0-macroF1:0.60191\n",
      "[100]\tvalidation_0-mlogloss:0.89729\tvalidation_0-macroF1:0.59552\n",
      "[150]\tvalidation_0-mlogloss:0.89797\tvalidation_0-macroF1:0.58308\n",
      "[200]\tvalidation_0-mlogloss:0.89707\tvalidation_0-macroF1:0.60787\n",
      "[250]\tvalidation_0-mlogloss:0.89636\tvalidation_0-macroF1:0.60327\n",
      "[299]\tvalidation_0-mlogloss:0.89568\tvalidation_0-macroF1:0.59413\n",
      "Train F1: 0.9177266968021762\n",
      "Test F1: 0.4169205363356127\n",
      "[12:36:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:36:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29873\tvalidation_0-macroF1:0.64866\n",
      "[50]\tvalidation_0-mlogloss:0.93059\tvalidation_0-macroF1:0.57796\n",
      "[100]\tvalidation_0-mlogloss:0.93042\tvalidation_0-macroF1:0.58456\n",
      "[150]\tvalidation_0-mlogloss:0.93141\tvalidation_0-macroF1:0.58464\n",
      "[200]\tvalidation_0-mlogloss:0.93280\tvalidation_0-macroF1:0.58348\n",
      "[250]\tvalidation_0-mlogloss:0.93234\tvalidation_0-macroF1:0.58326\n",
      "[299]\tvalidation_0-mlogloss:0.93234\tvalidation_0-macroF1:0.58357\n",
      "Train F1: 0.8890905288434153\n",
      "Test F1: 0.4291004079449764\n",
      "[12:37:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:37:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29814\tvalidation_0-macroF1:0.63167\n",
      "[50]\tvalidation_0-mlogloss:0.93109\tvalidation_0-macroF1:0.60363\n",
      "[100]\tvalidation_0-mlogloss:0.92695\tvalidation_0-macroF1:0.60890\n",
      "[150]\tvalidation_0-mlogloss:0.92862\tvalidation_0-macroF1:0.61470\n",
      "[200]\tvalidation_0-mlogloss:0.92751\tvalidation_0-macroF1:0.60809\n",
      "[250]\tvalidation_0-mlogloss:0.92977\tvalidation_0-macroF1:0.60797\n",
      "[299]\tvalidation_0-mlogloss:0.93202\tvalidation_0-macroF1:0.61026\n",
      "Train F1: 0.9022537754659561\n",
      "Test F1: 0.42152794153781975\n",
      "[12:37:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:37:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29890\tvalidation_0-macroF1:0.59884\n",
      "[50]\tvalidation_0-mlogloss:0.89680\tvalidation_0-macroF1:0.57203\n",
      "[100]\tvalidation_0-mlogloss:0.89428\tvalidation_0-macroF1:0.58095\n",
      "[150]\tvalidation_0-mlogloss:0.89336\tvalidation_0-macroF1:0.57380\n",
      "[200]\tvalidation_0-mlogloss:0.89353\tvalidation_0-macroF1:0.57258\n",
      "[250]\tvalidation_0-mlogloss:0.89322\tvalidation_0-macroF1:0.57108\n",
      "[299]\tvalidation_0-mlogloss:0.89235\tvalidation_0-macroF1:0.57199\n",
      "Train F1: 0.8938569029876557\n",
      "Test F1: 0.43980449162180346\n",
      "[12:38:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:38:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.30963\tvalidation_0-macroF1:0.63537\n",
      "[50]\tvalidation_0-mlogloss:0.92115\tvalidation_0-macroF1:0.58287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\tvalidation_0-mlogloss:0.91136\tvalidation_0-macroF1:0.58107\n",
      "[150]\tvalidation_0-mlogloss:0.90792\tvalidation_0-macroF1:0.56804\n",
      "[200]\tvalidation_0-mlogloss:0.90564\tvalidation_0-macroF1:0.56718\n",
      "[250]\tvalidation_0-mlogloss:0.90621\tvalidation_0-macroF1:0.56815\n",
      "[299]\tvalidation_0-mlogloss:0.90505\tvalidation_0-macroF1:0.57516\n",
      "Train F1: 0.9216674147144617\n",
      "Test F1: 0.43368257176436975\n",
      "[12:38:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[12:38:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[0]\tvalidation_0-mlogloss:1.29451\tvalidation_0-macroF1:0.62019\n",
      "[50]\tvalidation_0-mlogloss:0.87714\tvalidation_0-macroF1:0.57123\n",
      "[100]\tvalidation_0-mlogloss:0.87027\tvalidation_0-macroF1:0.57247\n",
      "[150]\tvalidation_0-mlogloss:0.86424\tvalidation_0-macroF1:0.56200\n",
      "[200]\tvalidation_0-mlogloss:0.86369\tvalidation_0-macroF1:0.55931\n",
      "[250]\tvalidation_0-mlogloss:0.86174\tvalidation_0-macroF1:0.56405\n",
      "[299]\tvalidation_0-mlogloss:0.86261\tvalidation_0-macroF1:0.56751\n",
      "Train F1: 0.9216788990707238\n",
      "Test F1: 0.4421686411590497\n"
     ]
    }
   ],
   "source": [
    "clfs = []\n",
    "for i in range(15):\n",
    "    clf = xgb.XGBClassifier(random_state=217+i, n_estimators=300, learning_rate=0.15, n_jobs=4, **opt_parameters)\n",
    "    \n",
    "    clfs.append(('xgb{}'.format(i), clf))\n",
    "    \n",
    "vc = VotingClassifierLGBM(clfs, voting='soft')\n",
    "del(clfs)\n",
    "\n",
    "#Train the final model with learning rate decay\n",
    "_ = vc.fit(X_train.drop(xgb_drop_cols, axis=1), y_train, sample_weight=y_train_weights, threshold=False, **fit_params)\n",
    "\n",
    "clf_final = vc.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score of a single LGBM Classifier: 0.8174\n",
      "Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: 0.9073\n",
      "Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: 0.9157\n"
     ]
    }
   ],
   "source": [
    "global_score = f1_score(y_test, clf_final.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "vc.voting = 'soft'\n",
    "global_score_soft = f1_score(y_test, vc.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "vc.voting = 'hard'\n",
    "global_score_hard = f1_score(y_test, vc.predict(X_test.drop(xgb_drop_cols, axis=1)), average='macro')\n",
    "\n",
    "print('Validation score of a single LGBM Classifier: {:.4f}'.format(global_score))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with soft voting strategy: {:.4f}'.format(global_score_soft))\n",
    "print('Validation score of a VotingClassifier on 3 LGBMs with hard voting strategy: {:.4f}'.format(global_score_hard))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'agg18_estadocivil4_COUNT',\n",
       " 'agg18_estadocivil5_COUNT',\n",
       " 'geo_energcocinar_LE_0',\n",
       " 'geo_epared_LE_2'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "useless_features = []\n",
    "drop_features = set()\n",
    "counter = 0\n",
    "for est in vc.estimators_:\n",
    "    ranked_features, unused_features = feature_importance(est, X_train.drop(xgb_drop_cols, axis=1), display_results=False)\n",
    "    useless_features.append(unused_features)\n",
    "    if counter == 0:\n",
    "        drop_features = set(unused_features)\n",
    "    else:\n",
    "        drop_features = drop_features.intersection(set(unused_features))\n",
    "    counter += 1\n",
    "    \n",
    "drop_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 114 (0.030279) - geo_epared_LE_1\n",
      "2. feature 42 (0.019682) - fe_children_fraction\n",
      "3. feature 74 (0.018983) - agg18_parentesco2_MEAN\n",
      "4. feature 59 (0.017248) - agg18_escolari_MAX\n",
      "5. feature 133 (0.016442) - geo_pared_LE_1\n",
      "6. feature 60 (0.014158) - agg18_escolari_MEAN\n",
      "7. feature 40 (0.013327) - SQBdependency\n",
      "8. feature 22 (0.012823) - dependency\n",
      "9. feature 34 (0.012632) - SQBescolari\n",
      "10. feature 12 (0.011761) - r4t1\n",
      "11. feature 37 (0.011632) - SQBedjefe\n",
      "12. feature 112 (0.011575) - geo_etecho_LE_1\n",
      "13. feature 126 (0.010669) - geo_sanitario_LE_3\n",
      "14. feature 96 (0.010495) - estadocivil_LE\n",
      "15. feature 116 (0.010293) - geo_elimbasu_LE_0\n",
      "16. feature 11 (0.010211) - r4m3\n",
      "17. feature 100 (0.010105) - geo_age\n",
      "18. feature 94 (0.010058) - etecho_LE\n",
      "19. feature 17 (0.009895) - male\n",
      "20. feature 105 (0.009877) - geo_hogar_total\n",
      "21. feature 87 (0.009871) - piso_LE\n",
      "22. feature 39 (0.009789) - SQBovercrowding\n",
      "23. feature 63 (0.009531) - agg18_estadocivil2_MEAN\n",
      "24. feature 117 (0.009491) - geo_elimbasu_LE_1\n",
      "25. feature 41 (0.009429) - SQBmeaned\n",
      "26. feature 95 (0.009387) - eviv_LE\n",
      "27. feature 49 (0.009266) - fe_mobile_density\n",
      "28. feature 104 (0.009116) - geo_hogar_adul\n",
      "29. feature 15 (0.009112) - cielorazo\n",
      "30. feature 23 (0.008963) - edjefe\n",
      "31. feature 93 (0.008881) - epared_LE\n",
      "32. feature 65 (0.008877) - agg18_estadocivil3_MEAN\n",
      "33. feature 124 (0.008846) - geo_sanitario_LE_1\n",
      "34. feature 109 (0.008796) - geo_eviv_LE_1\n",
      "35. feature 98 (0.008791) - tipovivi_LE\n",
      "36. feature 107 (0.008772) - geo_overcrowding\n",
      "37. feature 19 (0.008759) - hogar_adul\n",
      "38. feature 13 (0.008726) - r4t2\n",
      "39. feature 106 (0.008656) - geo_bedrooms\n",
      "40. feature 51 (0.008552) - fe_mobile_adult_density\n",
      "41. feature 27 (0.008478) - overcrowding\n",
      "42. feature 55 (0.008476) - agg18_age_MIN\n",
      "43. feature 31 (0.008450) - area1\n",
      "44. feature 58 (0.008433) - agg18_escolari_MIN\n",
      "45. feature 119 (0.008352) - geo_elimbasu_LE_3\n",
      "46. feature 14 (0.008237) - escolari\n",
      "47. feature 25 (0.008114) - meaneduc\n",
      "48. feature 86 (0.008095) - pared_LE\n",
      "49. feature 33 (0.008083) - age\n",
      "50. feature 7 (0.008060) - r4h2\n",
      "51. feature 120 (0.007983) - geo_elimbasu_LE_5\n",
      "52. feature 69 (0.007941) - agg18_estadocivil5_MEAN\n",
      "53. feature 97 (0.007922) - lugar_LE\n",
      "54. feature 123 (0.007897) - geo_sanitario_LE_0\n",
      "55. feature 35 (0.007885) - SQBage\n",
      "56. feature 71 (0.007873) - agg18_estadocivil6_MEAN\n",
      "57. feature 44 (0.007848) - fe_all_man_fraction\n",
      "58. feature 102 (0.007817) - geo_dependency\n",
      "59. feature 92 (0.007798) - elimbasu_LE\n",
      "60. feature 62 (0.007746) - agg18_estadocivil1_COUNT\n",
      "61. feature 45 (0.007711) - fe_human_density\n",
      "62. feature 0 (0.007631) - v2a1\n",
      "63. feature 56 (0.007629) - agg18_age_MAX\n",
      "64. feature 122 (0.007584) - geo_energcocinar_LE_3\n",
      "65. feature 8 (0.007526) - r4h3\n",
      "66. feature 136 (0.007525) - bedrooms_to_rooms\n",
      "67. feature 91 (0.007479) - energcocinar_LE\n",
      "68. feature 10 (0.007478) - r4m2\n",
      "69. feature 43 (0.007475) - fe_working_man_fraction\n",
      "70. feature 5 (0.007457) - v18q1\n",
      "71. feature 47 (0.007435) - fe_rent_per_person\n",
      "72. feature 4 (0.007360) - refrig\n",
      "73. feature 137 (0.007317) - rent_to_rooms\n",
      "74. feature 26 (0.007297) - bedrooms\n",
      "75. feature 128 (0.007238) - geo_manual_elec_LE_0\n",
      "76. feature 61 (0.007208) - agg18_dis_MEAN\n",
      "77. feature 24 (0.007182) - edjefa\n",
      "78. feature 30 (0.007106) - qmobilephone\n",
      "79. feature 85 (0.007052) - edjef\n",
      "80. feature 72 (0.006995) - agg18_estadocivil7_MEAN\n",
      "81. feature 36 (0.006962) - SQBhogar_total\n",
      "82. feature 90 (0.006927) - sanitario_LE\n",
      "83. feature 29 (0.006899) - television\n",
      "84. feature 21 (0.006897) - hogar_total\n",
      "85. feature 2 (0.006891) - rooms\n",
      "86. feature 125 (0.006886) - geo_sanitario_LE_2\n",
      "87. feature 16 (0.006851) - dis\n",
      "88. feature 18 (0.006810) - hogar_nin\n",
      "89. feature 143 (0.006710) - rent_to_hhsize\n",
      "90. feature 57 (0.006687) - agg18_age_MEAN\n",
      "91. feature 138 (0.006636) - tamhog_to_rooms\n",
      "92. feature 64 (0.006620) - agg18_estadocivil2_COUNT\n",
      "93. feature 52 (0.006611) - fe_tablet_adult_density\n",
      "94. feature 48 (0.006435) - fe_rent_per_room\n",
      "95. feature 6 (0.006235) - r4h1\n",
      "96. feature 1 (0.005999) - hacdor\n",
      "97. feature 99 (0.005923) - manual_elec_LE\n",
      "98. feature 129 (0.005903) - geo_manual_elec_LE_1\n",
      "99. feature 50 (0.005864) - fe_tablet_density\n",
      "100. feature 144 (0.005774) - rent_to_over_18\n",
      "101. feature 79 (0.005734) - agg18_parentesco7_MEAN\n",
      "102. feature 20 (0.005656) - hogar_mayor\n",
      "103. feature 89 (0.005596) - abastagua_LE\n",
      "104. feature 38 (0.005586) - SQBhogar_nin\n",
      "105. feature 111 (0.005451) - geo_etecho_LE_0\n",
      "106. feature 67 (0.005196) - agg18_estadocivil4_MEAN\n",
      "107. feature 88 (0.005127) - techo_LE\n",
      "108. feature 3 (0.005073) - hacapo\n",
      "109. feature 75 (0.004926) - agg18_parentesco3_MEAN\n",
      "110. feature 28 (0.004834) - computer\n",
      "111. feature 81 (0.004800) - agg18_parentesco9_MEAN\n",
      "112. feature 141 (0.004748) - v2a1_to_r4t3\n",
      "113. feature 9 (0.004701) - r4m1\n",
      "114. feature 140 (0.004519) - r4t3_to_rooms\n",
      "115. feature 77 (0.004361) - agg18_parentesco5_MEAN\n",
      "116. feature 53 (0.004182) - fe_people_not_living\n",
      "117. feature 32 (0.004033) - area2\n",
      "118. feature 78 (0.003952) - agg18_parentesco6_MEAN\n",
      "119. feature 83 (0.003865) - agg18_parentesco11_MEAN\n",
      "120. feature 101 (0.003449) - geo_meaneduc\n",
      "121. feature 76 (0.002761) - agg18_parentesco4_MEAN\n",
      "122. feature 142 (0.002618) - hhsize_to_rooms\n",
      "123. feature 84 (0.002575) - agg18_parentesco12_MEAN\n",
      "124. feature 139 (0.001424) - r4t3_to_tamhog\n",
      "125. feature 80 (0.001382) - agg18_parentesco8_MEAN\n",
      "126. feature 113 (0.000000) - geo_etecho_LE_2\n",
      "127. feature 134 (0.000000) - geo_pared_LE_2\n",
      "128. feature 68 (0.000000) - agg18_estadocivil4_COUNT\n",
      "129. feature 70 (0.000000) - agg18_estadocivil5_COUNT\n",
      "130. feature 46 (0.000000) - fe_human_bed_density\n",
      "131. feature 73 (0.000000) - agg18_parentesco1_MEAN\n",
      "132. feature 135 (0.000000) - geo_pared_LE_7\n",
      "133. feature 132 (0.000000) - geo_pared_LE_0\n",
      "134. feature 115 (0.000000) - geo_epared_LE_2\n",
      "135. feature 110 (0.000000) - geo_eviv_LE_2\n",
      "136. feature 130 (0.000000) - geo_manual_elec_LE_3\n",
      "137. feature 103 (0.000000) - geo_hogar_nin\n",
      "138. feature 54 (0.000000) - fe_people_weird_stat\n",
      "139. feature 127 (0.000000) - geo_sanitario_LE_4\n",
      "140. feature 66 (0.000000) - agg18_estadocivil3_COUNT\n",
      "141. feature 108 (0.000000) - geo_eviv_LE_0\n",
      "142. feature 82 (0.000000) - agg18_parentesco10_MEAN\n",
      "143. feature 121 (0.000000) - geo_energcocinar_LE_0\n",
      "144. feature 118 (0.000000) - geo_elimbasu_LE_2\n",
      "145. feature 131 (0.000000) - geo_manual_elec_LE_4\n"
     ]
    }
   ],
   "source": [
    "ranked_features = feature_importance(clf_final, X_train.drop(xgb_drop_cols, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 발표: 결정트리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score, roc_auc_score\n",
    "\n",
    "def get_clf_eval(y_test, pred):\n",
    "    confusion = confusion_matrix(y_test, pred)\n",
    "    accuracy= accuracy_score(y_test, pred)\n",
    "    precision= precision_score(y_test, pred)\n",
    "    recall = recall_score(y_test, pred)\n",
    "    f1= f1_score(y_test, pred)\n",
    "    roc_auc = roc_auc_score(y_test,pred_proba)\n",
    "    print('오차 행렬')\n",
    "    print(confusion)\n",
    "    print('정확도: {0:.4f}, 정밀도: {1:.4f}, 재현율: {2:.4f}, F1:{3:.4f}, AUC:{4:.4f}'.format(accuracy,precision,recall,f1,roc_auc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"prediction=dt_clf.predict(X_test.drop(et_drop_cols, axis=1))\\nprint('The accuracy of the Decision Tree is', accuracy_score(prediction,y_test))\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_clf=DecisionTreeClassifier(random_state=156) #Decision Tree\n",
    "dt_clf.fit(X_train.drop(et_drop_cols, axis=1),y_train)\n",
    "'''prediction=dt_clf.predict(X_test.drop(et_drop_cols, axis=1))\n",
    "print('The accuracy of the Decision Tree is', accuracy_score(prediction,y_test))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature importances:\n",
      "[0.002 0.002 0.016 0.002 0.004 0.017 0.001 0.007 0.009 0.006 0.004 0.007\n",
      " 0.004 0.005 0.014 0.    0.013 0.008 0.002 0.004 0.01  0.006 0.008 0.02\n",
      " 0.012 0.01  0.086 0.012 0.011 0.002 0.003 0.004 0.007 0.003 0.043 0.007\n",
      " 0.025 0.003 0.01  0.036 0.008 0.012 0.033 0.014 0.021 0.017 0.014 0.009\n",
      " 0.027 0.014 0.001 0.    0.013 0.013 0.017 0.002 0.001 0.009 0.013 0.005\n",
      " 0.016 0.016 0.024 0.024 0.    0.    0.015 0.004 0.001 0.002 0.004 0.002\n",
      " 0.003 0.    0.003 0.003 0.    0.002 0.004 0.002 0.001 0.001 0.001 0.001\n",
      " 0.004 0.001 0.003 0.    0.    0.001 0.    0.006 0.001 0.001 0.    0.001\n",
      " 0.001 0.006 0.006 0.003 0.001 0.    0.003 0.003 0.    0.001 0.    0.003\n",
      " 0.004 0.001 0.002 0.002 0.001 0.005 0.011 0.033 0.008 0.015 0.001 0.013\n",
      " 0.006 0.013 0.012 0.01 ]\n",
      "v2a1:0.002\n",
      "hacdor:0.002\n",
      "rooms:0.016\n",
      "hacapo:0.002\n",
      "refrig:0.004\n",
      "v18q1:0.017\n",
      "r4h1:0.001\n",
      "r4h2:0.007\n",
      "r4h3:0.009\n",
      "r4m1:0.006\n",
      "r4m2:0.004\n",
      "r4m3:0.007\n",
      "r4t1:0.004\n",
      "r4t2:0.005\n",
      "escolari:0.014\n",
      "rez_esc:0.000\n",
      "cielorazo:0.013\n",
      "dis:0.008\n",
      "male:0.002\n",
      "parentesco1:0.004\n",
      "idhogar:0.010\n",
      "hogar_nin:0.006\n",
      "hogar_adul:0.008\n",
      "hogar_mayor:0.020\n",
      "hogar_total:0.012\n",
      "dependency:0.010\n",
      "edjefe:0.086\n",
      "edjefa:0.012\n",
      "meaneduc:0.011\n",
      "bedrooms:0.002\n",
      "overcrowding:0.003\n",
      "computer:0.004\n",
      "television:0.007\n",
      "qmobilephone:0.003\n",
      "area1:0.043\n",
      "area2:0.007\n",
      "age:0.025\n",
      "SQBescolari:0.003\n",
      "SQBage:0.010\n",
      "SQBhogar_total:0.036\n",
      "SQBedjefe:0.008\n",
      "SQBhogar_nin:0.012\n",
      "SQBovercrowding:0.033\n",
      "SQBdependency:0.014\n",
      "SQBmeaned:0.021\n",
      "fe_children_fraction:0.017\n",
      "fe_working_man_fraction:0.014\n",
      "fe_all_man_fraction:0.009\n",
      "fe_human_density:0.027\n",
      "fe_human_bed_density:0.014\n",
      "fe_rent_per_person:0.001\n",
      "fe_rent_per_room:0.000\n",
      "fe_mobile_density:0.013\n",
      "fe_tablet_density:0.013\n",
      "fe_mobile_adult_density:0.017\n",
      "fe_tablet_adult_density:0.002\n",
      "fe_people_not_living:0.001\n",
      "fe_people_weird_stat:0.009\n",
      "agg18_age_MIN:0.013\n",
      "agg18_age_MAX:0.005\n",
      "agg18_age_MEAN:0.016\n",
      "agg18_escolari_MIN:0.016\n",
      "agg18_escolari_MAX:0.024\n",
      "agg18_escolari_MEAN:0.024\n",
      "agg18_dis_MEAN:0.000\n",
      "agg18_estadocivil1_MEAN:0.000\n",
      "agg18_estadocivil1_COUNT:0.015\n",
      "agg18_estadocivil2_MEAN:0.004\n",
      "agg18_estadocivil2_COUNT:0.001\n",
      "agg18_estadocivil3_MEAN:0.002\n",
      "agg18_estadocivil3_COUNT:0.004\n",
      "agg18_estadocivil4_MEAN:0.002\n",
      "agg18_estadocivil4_COUNT:0.003\n",
      "agg18_estadocivil5_MEAN:0.000\n",
      "agg18_estadocivil5_COUNT:0.003\n",
      "agg18_estadocivil6_MEAN:0.003\n",
      "agg18_estadocivil6_COUNT:0.000\n",
      "agg18_estadocivil7_MEAN:0.002\n",
      "agg18_estadocivil7_COUNT:0.004\n",
      "agg18_parentesco1_MEAN:0.002\n",
      "agg18_parentesco1_COUNT:0.001\n",
      "agg18_parentesco2_MEAN:0.001\n",
      "agg18_parentesco2_COUNT:0.001\n",
      "agg18_parentesco3_MEAN:0.001\n",
      "agg18_parentesco3_COUNT:0.004\n",
      "agg18_parentesco4_MEAN:0.001\n",
      "agg18_parentesco4_COUNT:0.003\n",
      "agg18_parentesco5_MEAN:0.000\n",
      "agg18_parentesco5_COUNT:0.000\n",
      "agg18_parentesco6_MEAN:0.001\n",
      "agg18_parentesco6_COUNT:0.000\n",
      "agg18_parentesco7_MEAN:0.006\n",
      "agg18_parentesco7_COUNT:0.001\n",
      "agg18_parentesco8_MEAN:0.001\n",
      "agg18_parentesco8_COUNT:0.000\n",
      "agg18_parentesco9_MEAN:0.001\n",
      "agg18_parentesco9_COUNT:0.001\n",
      "agg18_parentesco10_MEAN:0.006\n",
      "agg18_parentesco10_COUNT:0.006\n",
      "agg18_parentesco11_MEAN:0.003\n",
      "agg18_parentesco11_COUNT:0.001\n",
      "agg18_parentesco12_MEAN:0.000\n",
      "agg18_parentesco12_COUNT:0.003\n",
      "edjef:0.003\n",
      "pared_LE:0.000\n",
      "piso_LE:0.001\n",
      "techo_LE:0.000\n",
      "abastagua_LE:0.003\n",
      "sanitario_LE:0.004\n",
      "energcocinar_LE:0.001\n",
      "elimbasu_LE:0.002\n",
      "epared_LE:0.002\n",
      "etecho_LE:0.001\n",
      "eviv_LE:0.005\n",
      "estadocivil_LE:0.011\n",
      "parentesco_LE:0.033\n",
      "lugar_LE:0.008\n",
      "tipovivi_LE:0.015\n",
      "manual_elec_LE:0.001\n",
      "geo_age:0.013\n",
      "geo_meaneduc:0.006\n",
      "geo_dependency:0.013\n",
      "geo_hogar_nin:0.012\n",
      "geo_hogar_adul:0.010\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "feature_names = X_train.columns.tolist()[:]\n",
    "\n",
    "print(\"Feature importances:\\n{0}\".format(np.round(dt_clf.feature_importances_,3)))\n",
    "for name, value in zip(feature_names,dt_clf.feature_importances_):\n",
    "    print('{0}:{1:.3f}'.format(name,value))\n",
    "\n",
    "ftr_importances_values = dt_clf.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values, index=X_train.drop(et_drop_cols, axis=1).columns)\n",
    "ftr_top20=ftr_importances.sort_values(ascending=False)[:20]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances')\n",
    "sns.barplot(x=ftr_top20, y= ftr_top20.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최고 평균 정확도 수치: 0.5461\n",
      "GridSearchCV 최적 하이퍼 파라매터: {'max_depth': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    2.3s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>mean_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0.546138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>0.541076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0.526277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>0.525609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>0.494652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12</td>\n",
       "      <td>0.482888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>0.463377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20</td>\n",
       "      <td>0.456650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24</td>\n",
       "      <td>0.451939</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  param_max_depth  mean_test_score\n",
       "0               2         0.546138\n",
       "1               4         0.541076\n",
       "2               6         0.526277\n",
       "3               8         0.525609\n",
       "4              10         0.494652\n",
       "5              12         0.482888\n",
       "6              16         0.463377\n",
       "7              20         0.456650\n",
       "8              24         0.451939"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'max_depth' : [2,4,6,8,10,12,16,20,24]}\n",
    "grid_cv = GridSearchCV(dt_clf,param_grid=params, scoring = 'accuracy',cv=5,verbose=1)\n",
    "grid_cv.fit(X_train.drop(et_drop_cols, axis=1),y_train)\n",
    "print('GridSearchCV 최고 평균 정확도 수치: {0:.4f}'.format(grid_cv.best_score_))\n",
    "print('GridSearchCV 최적 하이퍼 파라매터:',grid_cv.best_params_)\n",
    "cv_results_df = pd.DataFrame(grid_cv.cv_results_)\n",
    "cv_results_df[['param_max_depth','mean_test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_depth=2 정확도: 0.6225\n",
      "max_depth=4 정확도: 0.6607\n",
      "max_depth=6 정확도: 0.6809\n",
      "max_depth=8 정확도: 0.7663\n",
      "max_depth=10 정확도: 0.8494\n",
      "max_depth=12 정확도: 0.9191\n",
      "max_depth=16 정확도: 0.9820\n",
      "max_depth=20 정확도: 0.9978\n"
     ]
    }
   ],
   "source": [
    "max_depths = [2,4,6,8,10,12,16,20]\n",
    "for depth in max_depths:\n",
    "    dt_clf = DecisionTreeClassifier(max_depth=depth,random_state=156)\n",
    "    dt_clf.fit(X_train.drop(et_drop_cols, axis=1),y_train)\n",
    "    pred = dt_clf.predict(X_test.drop(et_drop_cols, axis=1))\n",
    "    accuracy = accuracy_score(y_test,pred)\n",
    "    print('max_depth={0} 정확도: {1:.4f}'.format(depth,accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV 최고 평균 정확도 수치: 0.5461\n",
      "GridSearchCV 최적 하이퍼 파라미터: {'max_depth': 2, 'min_samples_split': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 120 out of 120 | elapsed:    5.9s finished\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'max_depth' : [2,4,6,8,10,12,16,20],\n",
    "    'min_samples_split' : [10,16,20],\n",
    "}\n",
    "grid_cv = GridSearchCV(dt_clf,param_grid=params, scoring = 'accuracy',cv=5,verbose=1)\n",
    "grid_cv.fit(X_train.drop(et_drop_cols, axis=1),y_train)\n",
    "print('GridSearchCV 최고 평균 정확도 수치: {0:.4f}'.format(grid_cv.best_score_))\n",
    "print('GridSearchCV 최적 하이퍼 파라미터:',grid_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결정 트리 예측 정확도:0.9978\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_dt_clf=grid_cv.best_estimator_\n",
    "pred1 = best_dt_clf.predict(X_test.drop(et_drop_cols, axis=1))\n",
    "accuarcy = accuracy_score(y_test,pred1)\n",
    "print('결정 트리 예측 정확도:{0:.4f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjUAAAF1CAYAAAAQpRtpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhdVZ3v//cHQiSSACogOISoDBEFAxRgmBHaAQfaFm9skbHtaDu1dmPfbrUR5Qqt2OoVm4tprwrKo1xQEVEhTgFkkFQgJKAJojiAKIQ5CBGS7++Ps+vHoagklaGqUrver+epJ+fsvfba370sqU/WWieVqkKSJGm022ikC5AkSVofDDWSJKkVDDWSJKkVDDWSJKkVDDWSJKkVDDWSJKkVDDWSxrwkH0jyhZGuQ9K6if9OjaR1keQ3wDOB5V2Hd6qqP6xjn2+tqh+uW3WjT5KTgR2q6i0jXYs02jhTI2l9eG1VTez6WutAsz4kGTeS919bo7VuaUNhqJE0JJJskeT/Jrkjye1J/leSjZtzL0jy4yR3J1mS5NwkWzbnvgJMBr6TZGmSf0lycJLb+vX/mySHNa9PTnJBkq8meQA4blX3H6DWk5N8tXk9JUklOT7J75Pcm+TtSfZKsiDJfUk+13XtcUmuTHJGkvuTLEpyaNf5ZyW5KMk9SW5J8vf97ttd99uBDwAzmme/oWl3fJJfJHkwya+TvK2rj4OT3Jbkn5Pc2Tzv8V3nJyT5zyS/ber7aZIJzbmXJrmqeaYbkhzc77l+3dzz1iRHreG3gDTs/FuBpKFyNvAnYAdgM+Bi4PfA54EApwGXA5sD3wBOBt5bVUcnOYCu5afuH7arcATwRuAY4CnA11Zx/8HYB9gROBC4CLgEOAzYBLg+yflVdVlX2wuArYC/Ab6Z5HlVdU9Tx03As4CpwA+S/LqqfrSSurfiyctPdwKvAX7d1PP9JHOr6rrm/LbAFsCzgb8CLkhyYVXdC3wSeBGwL/DHptYVSZ4NfBc4unm2Q4FvJJkK/Bn4LLBXVS1Osh3w9EGOmzRinKmRtD5c2Pxt/74kFyZ5JvAqOiHloaq6E/g08CaAqrqlqn5QVcuq6i7gU8BB61jD1VV1YVWtoBOUVnr/QTqlqh6pqtnAQ8DXqurOqroduALYvavtncBnqurRqjoPWAy8Oslzgf2B/9n0NR/4Ap0g8aS6q+rhgQqpqu9W1a+q4zJgNnBAV5NHgY829/8esBTYOclGwAnAP1bV7VW1vKquqqplwFuA71XV95p7/wDoBQ5v+lwBvDjJhKq6o6puWoOxk0aEMzWS1oe/7t7Um2RvOjMadyTpO7wRnZkSkmxDZybgAGBSc+7edazh912vt1/V/QfpT12vHx7g/cSu97fXEz918Vs6MzPPAu6pqgf7netZSd0DSvIq4MPATnSe46nAwq4md1fVY13v/9zUtxWwKfCrAbrdHnhjktd2HdsE+ElVPZRkBnAi8H+TXAn8c1UtWl2t0khypkbSUPg9sAzYqqq2bL42r6oXNedPAwrYrao2pzNrkK7r+38s8yE6P8gBaPbGbN2vTfc1q7v/+vbsdKUnOnuC/tB8PT3JpH7nbl9J3U96n+QpdJbnPgk8s6q2BL7HE8drZZYAjwAvGODc74GvdI3PllW1WVX9B0BVXVpVfwVsBywC/nsQ95NGlKFG0npXVXfQWSL5zySbJ9mo2Rzct8Q0ic4SyX3N3o739+viT8Dzu97fDGya5NVJNgE+RGf/ydref33bBnhPkk2SvBF4IZ2lnd8DVwGnJdk0yW7A3wHnrqKvPwFTmqUjgPF0nvUu4LFm1ublgymqWYr7IvCpZsPyxkmmN0Hpq8Brk7yiOb5ps+n4OUmemeR1STajEw6X8sSP7EsbJEONpKFyDJ0fyD+ns7R0AZ2/9QN8BNgDuJ/OZtVv9rv2NOBDzR6dE6vqfuAddPaj3E5n5uY2Vm1V91/ffkZnU/ES4GPAkVV1d3Pub4EpdGZtvgV8uNm/sjLnN3/eneS6ZunqPcD/o/Mcb6azcXmwTqSzVDUXuAf4OLBRE7iOoPNpq7vozNy8n87PhY2Af25qvofOfqd3rME9pRHhP74nSesgyXF0Pqm1/0jXIo11ztRIkqRWMNRIkqRWcPlJkiS1gjM1kiSpFQw1kiSpFfwXhUexrbbaqqZMmTLSZUiSNGzmzZu3pKr6/+ObgKFmVJsyZQq9vb0jXYYkScMmyW9Xds7lJ0mS1ArO1Ixiv7jtbvZ8/zkjXYYkSQOad/oxw3o/Z2okSVIrGGokSVIrGGokSVIrGGokSVIrGGokSVIrGGokSVIrGGokSVIrGGokSVIrGGokSVIrGGqGSZIpSW4c6TokSWorQ40kSWqFVoaaZlZkUZIvJLkxyblJDktyZZJfJtk7yWZJvphkbpLrkxzRde0VSa5rvvZtjh+cZE6SC5q+z02S5tyeSS5LMi/JpUm26zp+Q5KrgXd21Xdcks91vb84ycHN61c2970hyY+Gb9QkSRrd2vwLLXcA3gjMBOYCbwb2B14HfAD4OfDjqjohyZbAtUl+CNwJ/FVVPZJkR+BrQE/T5+7Ai4A/AFcC+yX5GXAGcERV3ZVkBvAx4ATgS8C7q+qyJKevruAkWwP/DRxYVbcmefoAbWY2z8T4Sc9Ym3GRJKmV2hxqbq2qhQBJbgJ+VFWVZCEwBXgO8LokJzbtNwUm0wksn0syDVgO7NTV57VVdVvT5/ymn/uAFwM/aCZuNgbuSLIFsGVVXdZc+xXgVaup+aXA5VV1K0BV3dO/QVXNAmYBbLbt82pwQyFJUvu1OdQs63q9ouv9CjrPvRx4Q1Ut7r4oycnAn4CX0Fmee2QlfS5v+glwU1VN79fPlsDKQsdjPHHpb9O+y1ZxjSRJWoVW7qkZpEuBd3fti9m9Ob4FcEdVrQCOpjPzsiqLga2TTG/62STJi6rqPuD+JPs37Y7quuY3wLQkGyV5LrB3c/xq4KAkz2v6etLykyRJGthYDjWnAJsAC5qPWp/SHD8TODbJNXSWnh5aVSdV9RfgSODjSW4A5gP7NqePB/6r2Sj8cNdlVwK3AguBTwLXNX3dRWe/zDebvs5b14eUJGmsSJWrHaPVZts+r6Ye/ZGRLkOSpAHNO/2Y9d5nknlV1TPQubE8UyNJklrEUCNJklrBUCNJklrBUCNJklrBUCNJklrBUCNJklrBUCNJklqhzb8mofVe+Jxn0DsE/waAJEmjkTM1kiSpFQw1kiSpFQw1kiSpFQw1kiSpFQw1kiSpFQw1kiSpFfxI9yj2lztu4ncf3XWky9AoNPmkhSNdgiStd87USJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVtjgQk2SDya5KcmCJPOT7JNkfJLPJPlVkluSXJxkctc1y5u2NyS5Lsm+zfGDk1w8ck+zekm+kGSXka5DkqTRboP6NQlJpgOvAfaoqmVJtgLGA6cCk4Cdqmp5kuOBbyfZs6pWAA9X1bSmj1cApwEHjUD946rqsTW5pqreOlT1SJI0lmxoMzXbAUuqahlAVS0B7gOOB95XVcub418ClgKHDdDH5sC9Xe8nJrkgyaIk5yYJQJJDk1yfZGGSLyZ5SnP88KbtT5N8tm+mJ8neSa5qrrkqyc7N8eOSnJ/kO8DsgR6qmTGas5I65iTpaV4vTfKxZsbpmiTPXLfhlCRp7NjQQs1s4LlJbk5yZpKDgB2A31XVA/3a9gJ9yzYTmuWnRcAXgFO62u0OvLdp+3xgvySbAl8GZlTVrnRmrP6hOf554FVVtT+wdVc/i4ADq2p34CQ6s0d9pgPHVtXLVvFsT6pjgDabAddU1UuAy4G/798gycwkvUl673lo+SpuJ0nS2LJBhZqqWgrsCcwE7gLOAw4BaoDm6Xr9cFVNq6qpwCuBc/pmQoBrq+q2ZplqPjAF2Bm4tapubtqcDRwITAV+XVW3Nse/1nWPLYDzk9wIfBp4Ude5H1TVPat5vIHq6O8vQN8eoHkDtamqWVXVU1U9T99s49XcUpKksWODCjUAVbW8quZU1YeBd9HZY7N9kkn9mu5BZ7am//VXA1vx+CzLsq7Ty+nMyqT/dY2VHYfO7M9PqurFwGuBTbvOPbSK6/oMVEd/j1ZVraaNJEkawAYVapLsnGTHrkPTgMV0ZlI+lWTjpt0xwCPAlQP0MRXYGLh7FbdaBExJskPz/mjgsub485NMaY7P6LpmC+D25vVxg34oSZI0LDa0mYCJwBlJtgQeA26hsxT1IHA6sDjJBDpLU9O7ZjUmJJnfvA6d/S3LH1+BeqKqeqT5BNX5ScYBc4Gzmk9cvQO4JMkS4Nquyz4BnJ3kn4Afr8dnliRJ60EezwWjQ5JtgUuAM6tq1hD0P7GqljZ7cv4L+GVVfXp932d92O3ZE+rit+2w+oZSP5NPWjjSJUjSWkkyr6p6Bjq3oc3UrFZV/ZHOstRQ+fskx9L593Gup/NpKEmStIEbdaFmqDWzMms1M5NkV+Ar/Q4vq6p91rkwSZK0Soaa9aiqFjK0s0iSJGklNqhPP0mSJK0tQ40kSWoFQ40kSWoFQ40kSWoFNwqPYuO3exGTT3rSb4qQJGlMcqZGkiS1gqFGkiS1gqFGkiS1gqFGkiS1gqFGkiS1gp9+GsUW3bmI/c7Yb6TLaK0r333lSJcgSVoDztRIkqRWMNRIkqRWMNRIkqRWMNRIkqRWMNRIkqRWMNRIkqRWMNRIkqRWMNRIkqRWMNRIkqRWMNRIkqRWMNSsgyRXrcU1Bye5eIDjc5IsTjK/+bpg/VQpSdLY4O9+WgdVte967vKoqupdz31KkjQmOFPTT5K3JLm2mS35fJJ3JvlE1/njkpzRvF7a/HleksO72nw5yRuGqL6ZSXqT9D669NGhuIUkSaOSoaZLkhcCM4D9qmoasBxYCvxNV7MZwHn9Lv16c5wk44FDge+tRQnndi0/nT5Qg6qaVVU9VdWzycRN1uIWkiS1k8tPT3QosCcwNwnABOBO4NdJXgr8EtgZuLLfdd8HPpvkKcArgcur6uG1uL/LT5IkrSVDzRMFOLuq/u0JB5O/A/4HsAj4VlVV9/mqeiTJHOAVdGZsvjY85UqSpD4uPz3Rj4Ajk2wDkOTpSbYHvgn8NfC3PHnpqc/XgeOBA4BLh6FWSZLUxZmaLlX18yQfAmYn2Qh4FHhnVf02yc+BXarq2pVcPhs4B7ioqv6ymlsdmuS2rvdvbP48N0nfstWSqjpsLR9FkqQxx1DTT1WdxwCzMVX1mgGOTex6/SjwjEH0P4fOXp3+Dl6TOiVJ0hO5/CRJklrBmZohkuQVwMf7Hb61ql4/EvVIktR2hpohUlWX4oZhSZKGjctPkiSpFQw1kiSpFQw1kiSpFdxTM4pN3WYqV767/29skCRpbHKmRpIktYKhRpIktYKhRpIktYKhRpIktYKhRpIktYKhRpIktYKhRpIktYKhRpIktYKhRpIktYKhRpIktYKhRpIktYKhRpIktYKhRpIktYKhRpIktYKhRpIktYKhRpIktcJqQ02S9yT5RZJz1/VmSaYkubF5fXCSi9e1z/UlydeSLEjyvvXQ1wf6vb9qXfuUJEmrNm4Qbd4BvKqqbh3qYkZKkm2Bfatq+wHOjauqx9awyw8Ap/a9qap917FESZK0GqucqUlyFvB84KIkH0zyxSRzk1yf5IhVXDclyRVJrmu+1viHepKTk5ydZHaS3yT5mySfSLIwySVJNmnandTUdGOSWUnSHJ+T5ONJrk1yc5IDVnG72cA2SeYnOaC59tQklwH/mOS1SX7WPPcPkzyzucfEJF9qalqQ5A1J/gOY0PR1btNuafNnkpze1LowyYzm+MHNPS9IsijJuX3PIUmSBmeVoaaq3g78ATgE2Az4cVXt1bw/PclmK7n0TuCvqmoPYAbw2bWs7wXAq4EjgK8CP6mqXYGHm+MAn6uqvarqxcAE4DVd14+rqr2B9wIfXsV9Xgf8qqqmVdUVzbEtq+qgqvpP4KfAS6tqd+DrwL80bf4duL+qdq2q3eiMz78CDzd9HdXvPn8DTANeAhxGZwy3a87t3tS5C50gud9AhSaZmaQ3Se9dd921ikeSJGlsGczyU5+XA69LcmLzflNgMvCLAdpuAnwuyTRgObDTWtb3/ap6NMlCYGPgkub4QmBK8/qQJP8CPBV4OnAT8J3m3DebP+d1tR+s87pePwc4rwkg44G+pbjDgDf1Naqqe1fT5/7A16pqOfCnZiZoL+AB4Nqqug0gyfym3p/276CqZgGzAHp6emoNn0mSpNZak1AT4A1VtXgQbd8H/InOjMRGwCNrURvAMoCqWpHk0arq+yG+AhiXZFPgTKCnqn6f5GQ6YesJ19MJVmvyrAAPdb0+A/hUVV2U5GDg5OZ4gDUJFqtaUlrW9Xpt6pUkaUxbk490Xwq8u2vPyu6raLsFcEdVrQCOpjPLMhT6AsySJBOBI4foPlsAtzevj+06Pht4V9+bJE9rXj7at+enn8uBGUk2TrI1cCBw7RDUK0nSmLMmoeYUOstKC5qPZZ+yirZnAscmuYbO0tNDq2i71qrqPuC/6SxHXQjMHYr70JmZOT/JFcCSruP/C3has/H3Bjp7jaCzPLRggI/BfwtYANwA/Bj4l6r64xDVLEnSmJLHV3Q02vT09FRvb+9IlyFJ0rBJMq+qegY6578oLEmSWmGdNqMmeQXw8X6Hb62q169BH8cD/9jv8JVV9c51qW0l91rneiVJ0obJ5adRzOUnSdJY4/KTJElqPUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUONJElqBUPNBiLJuUkWJ7kxyReTbDLSNUmSNJoYaoZAko3X4rJzganArsAE4K3rtShJklrOULMWklyYZF6Sm5LMbI4tTfLRJD8Dpid5S5Jrk8xP8vm+oJPk/yTpba79SF+fVfW9agDXAs8ZkYeTJGmUMtSsnROqak+gB3hPkmcAmwE3VtU+wN3ADGC/qpoGLAeOaq79YFX1ALsBByXZrbvjZtnpaOCSgW6cZGYTinrvuuuuoXg2SZJGpXEjXcAo9Z4kr29ePxfYkU5w+UZz7FBgT2BuEugsJ93ZnPsfzezOOGA7YBdgQVffZwKXV9UVA924qmYBswB6enpqfT2QJEmjnaFmDSU5GDgMmF5Vf04yB9gUeKSqlvc1A86uqn/rd+3zgBOBvarq3iRfbq7tO/9hYGvgbUP9HJIktY3LT2tuC+DeJtBMBV46QJsfAUcm2QYgydOTbA9sDjwE3J/kmcCr+i5I8lbgFcDfVtWKoX4ISZLaxpmaNXcJ8PYkC4DFwDX9G1TVz5N8CJidZCPgUeCdVXVNkuuBm4BfA1d2XXYW8Fvg6mbJ6ptV9dGhfRRJktrDULOGqmoZXTMsXSb2a3cecN4A1x+3kn7930KSpHXg8pMkSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ40kSWoFQ80QSnJhknlJbkoyszn2d0luTjInyX8n+VxzfOsk30gyt/nab2SrlyRpdBk30gW03AlVdU+SCcDcJN8F/h3YA3gQ+DFwQ9P2fwOfrqqfJpkMXAq8sH+HTTiaCTB58uRheARJkkYHQ83Qek+S1zevnwscDVxWVfcAJDkf2Kk5fxiwS5K+azdPMqmqHuzusKpmAbMAenp6aojrlyRp1DDUDJEkB9MJKtOr6s9J5gCLGWD2pbFR0/bh4alQkqR2cU/N0NkCuLcJNFOBlwJPBQ5K8rQk44A3dLWfDbyr702SacNarSRJo5yhZuhcAoxLsgA4BbgGuB04FfgZ8EPg58D9Tfv3AD1JFiT5OfD24S9ZkqTRy+WnIVJVy4BX9T+epLeqZjUzNd+iM0NDVS0BZgxvlZIktYczNcPv5CTzgRuBW4ELR7geSZJawZmaYVZVJ450DZIktZEzNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRVGbahJ8sEkNyVZkGR+kn2SjE/ymSS/SnJLkouTTO66ZnnT9oYk1yXZdxjqPDjJxWt4zbOSXDBUNUmS1EbjRrqAtZFkOvAaYI+qWpZkK2A8cCowCdipqpYnOR74dpI9q2oF8HBVTWv6eAVwGnDQyDzFwJKMq6o/AEeOdC2SJI0mo3WmZjtgSVUtA6iqJcB9wPHA+6pqeXP8S8BS4LAB+tgcuLfvTZL3J5nbzPx8pDm2WZLvNjM7NyaZ0RzfK8lVzfFrk0xKsmmSLyVZmOT6JIf0v2GSvZvrrm/+3Lk5flyS85N8B5idZEqSG9fjeEmS1HqjcqYGmA2clORm4IfAeXQCyu+q6oF+bXuBXZprJiSZD2xKJxi9DCDJy4Edgb2BABclORDYGvhDVb26abdFkvHN/WZU1dwkmwMPA/8IUFW7JplKJ5zs1K+WRcCBVfVYksPozCy9oTk3Hditqu5JMmWdR0iSpDFmVIaaqlqaZE/gAOAQOiHjNKAGaJ6u193LT9OBc5K8GHh583V9024inZBzBfDJJB8HLq6qK5LsCtxRVXObWh5o+tsfOKM5tijJb4H+oWYL4OwkOza1btJ17gdVdc/qnj3JTGAmwOTJk1fTWpKksWNUhhqAZolpDjAnyULgbcD2SSZV1YNdTfcAnrTptqqubvbibE0n+JxWVZ/v364JT4cDpyWZDVzI6sPTypwC/KSqXt/MxszpOvfQIK6nqmYBswB6enoGqkOSpDFpVO6pSbJzM9vRZxqwGDgb+FSSjZt2xwCPAFcO0MdUYGPgbuBS4IQkE5tzz06yTZJnAX+uqq8Cn6QTkBYBz0qyV9N2UpJxwOXAUc2xnYDJTU3dtgBub14ft06DIEmSnmC0ztRMBM5IsiXwGHALnSWZB4HTgcVJJgB3AdOrqm9Go29PDXRmVo5tZnxmJ3khcHUS6GwufguwA3B6khXAo8A/VNVfmg3DZzT3eJjORuQzgbOaWaPHgOOaT2Z11/0JOstP/wT8eP0PiyRJY1ce/3nfLkm2BS4BzmyWbFqnp6enent7R7oMSZKGTZJ5VdUz0LnROlOzWlX1RzrLUpIkaQwYlXtqJEmS+jPUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUSJKkVjDUdEnywSQ3JVmQZH6SfZKMT/KZJL9KckuSi5NM7rpmedP2hiTXJdl3JJ9BkqSxatxIF7ChSDIdeA2wR1UtS7IVMB44FZgE7FRVy5McD3w7yZ5VtQJ4uKqmNX28AjgNOGhknkKSpLHLmZrHbQcsqaplAFW1BLgPOB54X1Utb45/CVgKHDZAH5sD9wIkmZjkR83szcIkR/Q1SvLvSRYl+UGSryU5sTn+giSXJJmX5IokU4fygSVJahNnah43Gzgpyc3AD4Hz6ASU31XVA/3a9gK7NNdMSDIf2JROMHpZ0+YR4PVV9UAz63NNkouAPYE3ALvTGf/rgHnNNbOAt1fVL5PsA5zZ1R8ASWYCMwEmT56MJEnqMNQ0qmppkj2BA4BD6ISa04AaoHm6XncvP00Hzkny4qbNqUkOBFYAzwaeCewPfLuqHm6u+U7z50RgX+D85P/v/ikD1DmLTvihp6dnoNokSRqTDDVdmiWmOcCcJAuBtwHbJ5lUVQ92Nd0DuGCA669uZmW2Bg5v/tyzqh5N8hs6sznpf11jI+C+voAkSZLWjHtqGkl2TrJj16FpwGLgbOBTSTZu2h1DZ2npygH6mApsDNwNbAHc2QSaQ4Dtm2Y/BV6bZNNmdubVAM0S161J3tj0lSQvGYJHlSSplZypedxE4IwkWwKPAbfQ2bvyIHA6sDjJBOAuYHpV9S399O2pgc4szLHNp6TOBb6TpBeYDywCqKq5zd6aG4Df0tmfc39z/VHA/0nyIWAT4OtNO0mStBp5/GezVifJtsAlwJnN3pa17Wdis4fnqcDlwMyqum5N++np6ane3t61LUOSpFEnybyq6hnonDM1a6Cq/khnWWpdzUqyC509NmevTaCRJElPZKgZAVX15pGuQZKktnGjsCRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJagVDjSRJaoVhDzVJPpjkpiQLksxPsk+S8Uk+k+RXSW5JcnGSyV3XLG/a3pDkuiT7NscPTnLxcD9Df0mmJHnzINpNS3L4INptEM8lSdJoMqyhJsl04DXAHlW1G3AY8HvgVGASsFNV7QB8A/h2kr76Hq6qaVX1EuDfgNOGs+4+Scat5NQUYLWhBpgGrDbUSJKkNTfcMzXbAUuqahlAVS0B7gOOB95XVcub418CltIJPf1tDtzb9X5ikguSLEpybpIAJDk0yfVJFib5YpKnNMcPb9r+NMln+2ZEkuyd5KrmmquS7NwcPy7J+Um+A8xeyXP9B3BAM5v0viSbJvlSc+/rkxySZDzwUWBG027Gyu4pSZLW3MpmHobKbOCkJDcDP+j7J18AAAq8SURBVATOoxNQfldVD/Rr2wvs0lwzIcl8YFM6wehlXe12B14E/AG4EtgvSS/wZeDQqro5yTnAPyQ5C/g8cGBV3Zrka139LGqOP5bkMDqzR29ozk0Hdquqe1byXP8KnFhVrwFI8s8AVbVrkqnNM+wEnAT0VNW7mnabr+KeA0oyE5gJMHny5FU1lSRpTBnWmZqqWgrsSeeH8l10Qs0hQA3QPF2v+5afpgKvBM7pm5EBrq2q26pqBTCfzlLQzsCtVXVz0+Zs4EBgKvDrqrq1Od4darYAzk9yI/BpOkGpzw9WEWgGsj/wleaZFwG/pRNq+lvVPQdUVbOqqqeqerbeeus1KEmSpHYb9o3CVbW8quZU1YeBd9HZY7N9kkn9mu5BZ7am//VXA1sBfT/Rl3WdXk5n9in9r2us7DjAKcBPqurFwGvpzAr1eWgV163pfQZ7T0mStAaGe6Pwzkl27Do0DVhMZyblU0k2btodAzxCZzmpfx9TgY2Bu1dxq0XAlCQ7NO+PBi5rjj8/yZTm+Iyua7YAbm9eHzfoh+p4kM5G5z6XA0c19e4ETKbznP3brcs9JUlSl+HeUzMROCPJlsBjwC10lqIeBE4HFieZQGdpanpV9S1L9e2pgc4syLFVtfzxFagnqqpHkhxPZ2lnHDAXOKuqliV5B3BJkiXAtV2XfQI4O8k/AT9ew+daADyW5AY6e3nOBM5KsrB5zuOae/8E+NfmWU5bx3tKkqQueTw3bBiSbAtcApxZVbOGoP+JVbW02ZPzX8Avq+rT6/s+w6Gnp6d6e5+0QidJUmslmVdVPQOdG+6ZmtWqqj/SWZYaKn+f5FhgPHA9nU9DSZKkUW6DCzVDrZmVWauZmSS70nyqqcuyqtpnnQuTJEnrZMyFmnVRVQsZ2lkkSZK0lvyFlpIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRUMNZIkqRVaG2qSfDDJTUkWJJmfZJ8k45N8JsmvktyS5OIkk7uuWd60vSHJdUn2XcN7npzkxOb1R5Mctpr2U5v7XZ/kBWv3pJIkCWDcSBcwFJJMB14D7FFVy5JsBYwHTgUmATtV1fIkxwPfTrJnVa0AHq6qaU0frwBOAw5amxqq6qRBNPtr4NtV9eG1uYckSXpcW2dqtgOWVNUygKpaAtwHHA+8r6qWN8e/BCwFBppR2Ry4t+9NkvcnmdvM/Hyk6/gHkyxO8kNg567jX05yZPN6zySXJZmX5NIk2yU5HHgv8NYkP2navSXJtc3szeeTbLxeR0WSpBZr5UwNMBs4KcnNwA+B8+gElN9V1QP92vYCuzTXTEgyH9iUTjB6GUCSlwM7AnsDAS5KciDwEPAmYHc6Y3kdMK+78ySbAGcAR1TVXUlmAB+rqhOSnAUsrapPJnkhMAPYr6oeTXImcBRwTr/+ZgIzASZPnowkSepoZaipqqVJ9gQOAA6hE2pOA2qA5ul63b38NB04J8mLgZc3X9c37SbSCTmTgG9V1Z+bay4aoP+dgRcDP0gCsDFwxwDtDgX2BOY27SYAdw7wbLOAWQA9PT0DPY8kSWNSK0MNQLPENAeYk2Qh8DZg+ySTqurBrqZ7ABcMcP3VzV6crekEn9Oq6vPdbZK8l4GD0hOaATdV1fRBtDu7qv5tNe0kSdIAWrmnJsnOSXbsOjQNWAycDXyqb69KkmOAR4ArB+hjKp1ZlbuBS4ETkkxszj07yTbA5cDrk0xIMgl47QDlLAa2bmZ+SLJJkhcN0O5HwJFNvyR5epLt1+LxJUkak9o6UzMROCPJlsBjwC109qE8CJwOLE4yAbgLmF5VfbMtfXtqoDNzcmwz4zO72fNydbM0tBR4S1Vdl+Q8YD7wW+CKfnVUVf2l2TD82SRb0BnzzwA39Wv48yQfau61EfAo8M6mX0mStBp5/Of52JJkW+AS4Mxmn8r67v87wKeq6ifru+8+PT091dvbO1TdS5K0wUkyr6p6BjrX1pma1aqqP9JZllrvknwReCrw06HoX5IkPdmYDTVDqapOGOkaJEkaa1q5UViSJI09hhpJktQKhhpJktQKhhpJktQKhhpJktQKhhpJktQKhhpJktQKhhpJktQKhhpJktQKY/Z3P7VBkgfp/BbwsW4rYMlIFzHCHIMOx8Ex6OM4tHcMtq+qrQc64a9JGN0Wr+yXeo0lSXrH+jg4Bh2Og2PQx3EYm2Pg8pMkSWoFQ40kSWoFQ83oNmukC9hAOA6OQR/HwTHo4ziMwTFwo7AkSWoFZ2okSVIrGGpGgSSvTLI4yS1J/nWA80ny2eb8giR7jESdQ20Q4zA1ydVJliU5cSRqHGqDGIOjmu+BBUmuSvKSkahzqA1iHI5oxmB+kt4k+49EnUNpdWPQ1W6vJMuTHDmc9Q2XQXwvHJzk/uZ7YX6Sk0aizqE0mO+FZhzmJ7kpyWXDXeOwqSq/NuAvYGPgV8DzgfHADcAu/docDnwfCPBS4GcjXfcIjcM2wF7Ax4ATR7rmERqDfYGnNa9fNYa/Fyby+PL6bsCika57uMegq92Pge8BR4503SP0vXAwcPFI1zrCY7Al8HNgcvN+m5Gue6i+nKnZ8O0N3FJVv66qvwBfB47o1+YI4JzquAbYMsl2w13oEFvtOFTVnVU1F3h0JAocBoMZg6uq6t7m7TXAc4a5xuEwmHFYWs1/vYHNgLZtHhzMfxcA3g18A7hzOIsbRoMdhzYbzBi8GfhmVf0OOv+tHOYah42hZsP3bOD3Xe9va46taZvRbiw84+qs6Rj8HZ0ZvLYZ1DgkeX2SRcB3gROGqbbhstoxSPJs4PXAWcNY13Ab7P8npie5Icn3k7xoeEobNoMZg52ApyWZk2RekmOGrbph5r8ovOHLAMf6/61zMG1Gu7HwjKsz6DFIcgidUNO6vSQMchyq6lvAt5IcCJwCHDbUhQ2jwYzBZ4D/WVXLk4Gat8JgxuE6Ov+s/tIkhwMXAjsOeWXDZzBjMA7YEzgUmABcneSaqrp5qIsbboaaDd9twHO73j8H+MNatBntxsIzrs6gxiDJbsAXgFdV1d3DVNtwWqPvhaq6PMkLkmxVVW35PTiDGYMe4OtNoNkKODzJY1V14fCUOCxWOw5V9UDX6+8lOXMMfi/cBiypqoeAh5JcDrwEaF2ocflpwzcX2DHJ85KMB94EXNSvzUXAMc2noF4K3F9Vdwx3oUNsMOPQdqsdgySTgW8CR7fxb2GNwYzDDml+mjefBhwPtCngrXYMqup5VTWlqqYAFwDvaFmggcF9L2zb9b2wN52fe2PqewH4NnBAknFJngrsA/ximOscFs7UbOCq6rEk7wIupbPL/YtVdVOStzfnz6LzyYbDgVuAPwPHj1S9Q2Uw45BkW6AX2BxYkeS9dD4F8MBKOx5FBvm9cBLwDODM5r/jj1XLfqHdIMfhDXSC/qPAw8CMro3Do94gx6D1BjkORwL/kOQxOt8Lbxpr3wtV9YsklwALgBXAF6rqxpGreuj4LwpLkqRWcPlJkiS1gqFGkiS1gqFGkiS1gqFGkiS1gqFGkiS1gqFGkiS1gqFGkiS1gqFGkiS1wv8H8VDT/t+EoZwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ftr_importances_values = best_dt_clf.feature_importances_\n",
    "ftr_importances = pd.Series(ftr_importances_values, index=X_train.drop(et_drop_cols, axis=1).columns)\n",
    "ftr_top10=ftr_importances.sort_values(ascending=False)[:10]\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.title('Feature importances')\n",
    "sns.barplot(x=ftr_top10, y= ftr_top10.index)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
